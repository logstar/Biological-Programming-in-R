
@article{_contingency_2018,
  title = {Contingency Table},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {In statistics, a contingency table (also known as a cross tabulation or crosstab) is a type of table in a matrix format that displays the (multivariate) frequency distribution of the variables. They are heavily used in survey research, business intelligence, engineering and scientific research. They provide a basic picture of the interrelation between two variables and can help find interactions between them. The term contingency table was first used by Karl Pearson in "On the Theory of Contingency and Its Relation to Association and Normal Correlation", part of the Drapers' Company Research Memoirs Biometric Series I published in 1904.
A crucial problem of multivariate statistics is finding (direct-)dependence structure underlying the variables contained in high-dimensional contingency tables. If some of the conditional independences are revealed, then even the storage of the data can be done in a smarter way (see Lauritzen (2002)). In order to do this one can use information theory concepts, which gain the information only from the distribution of probability, which can be expressed easily from the contingency table by the relative frequencies.},
  language = {en},
  journal = {Wikipedia},
  month = feb,
  year = {2018},
  file = {/Users/zhangy4/Zotero/storage/I5VZDLN3/index.html},
  note = {Page Version ID: 823753141}
}

@article{_mcnemar_2017,
  title = {{{McNemar}}'s Test},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {In statistics, McNemar's test is a statistical test used on paired nominal data. It is applied to 2 \texttimes{} 2 contingency tables with a dichotomous trait, with matched pairs of subjects, to determine whether the row and column marginal frequencies are equal (that is, whether there is "marginal homogeneity"). It is named after Quinn McNemar, who introduced it in 1947. An application of the test in genetics is the transmission disequilibrium test for detecting linkage disequilibrium.},
  language = {en},
  journal = {Wikipedia},
  month = nov,
  year = {2017},
  file = {/Users/zhangy4/Zotero/storage/VENXTFXV/index.html},
  note = {Page Version ID: 809741672}
}

@article{_fisher_2018a,
  title = {Fisher's Exact Test},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {Fisher's exact test is a statistical significance test used in the analysis of contingency tables. Although in practice it is employed when sample sizes are small, it is valid for all sample sizes. It is named after its inventor, Ronald Fisher, and is one of a class of exact tests, so called because the significance of the deviation from a null hypothesis (e.g., P-value) can be calculated exactly, rather than relying on an approximation that becomes exact in the limit as the sample size grows to infinity, as with many statistical tests.
Fisher is said to have devised the test following a comment from Muriel Bristol, who claimed to be able to detect whether the tea or the milk was added first to her cup. He tested her claim in the "lady tasting tea" experiment.},
  language = {en},
  journal = {Wikipedia},
  month = jan,
  year = {2018},
  file = {/Users/zhangy4/Zotero/storage/ABWSSQY3/index.html},
  note = {Page Version ID: 823327889}
}

@misc{_comparing_,
  title = {Comparing {{Two Proportions}} | {{STAT}} 414 / 415},
  howpublished = {https://onlinecourses.science.psu.edu/stat414/node/268},
  file = {/Users/zhangy4/Zotero/storage/2HGLD9Y7/268.html}
}

@article{_chisquared_2018,
  title = {Chi-Squared Test},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {A chi-squared test, also written as $\chi$2 test, is any statistical hypothesis test where the sampling distribution of the test statistic is a chi-squared distribution when the null hypothesis is true. Without other qualification, 'chi-squared test' often is used as short for Pearson's chi-squared test. The chi-squared test is used to determine whether there is a significant difference between the expected frequencies and the observed frequencies in one or more categories.
In the standard applications of the test, the observations are classified into mutually exclusive classes, and there is some theory, or say null hypothesis, which gives the probability that any observation falls into the corresponding class. The purpose of the test is to evaluate how likely it is that the null hypothesis is true, given the observations.
Chi-squared tests are often constructed from a sum of squared errors, or through the sample variance. Test statistics that follow a chi-squared distribution arise from an assumption of independent normally distributed data, which is valid in many cases due to the central limit theorem. A chi-squared test can be used to attempt rejection of the null hypothesis that the data are independent.
Also considered a chi-squared test is a test in which this is asymptotically true, meaning that the sampling distribution (if the null hypothesis is true) can be made to approximate a chi-squared distribution as closely as desired by making the sample size large enough.},
  language = {en},
  journal = {Wikipedia},
  month = feb,
  year = {2018},
  file = {/Users/zhangy4/Zotero/storage/C58L7LCB/index.html},
  note = {Page Version ID: 824098097}
}

@misc{_comparing_a,
  title = {8.1 - {{Comparing Two Population Proportions}} with {{Independent Samples}} | {{STAT}} 500},
  howpublished = {https://onlinecourses.science.psu.edu/stat500/node/55},
  file = {/Users/zhangy4/Zotero/storage/J7TTD5PI/55.html}
}

@article{_contingency_2018a,
  title = {Contingency Table},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {In statistics, a contingency table (also known as a cross tabulation or crosstab) is a type of table in a matrix format that displays the (multivariate) frequency distribution of the variables. They are heavily used in survey research, business intelligence, engineering and scientific research. They provide a basic picture of the interrelation between two variables and can help find interactions between them. The term contingency table was first used by Karl Pearson in "On the Theory of Contingency and Its Relation to Association and Normal Correlation", part of the Drapers' Company Research Memoirs Biometric Series I published in 1904.
A crucial problem of multivariate statistics is finding (direct-)dependence structure underlying the variables contained in high-dimensional contingency tables. If some of the conditional independences are revealed, then even the storage of the data can be done in a smarter way (see Lauritzen (2002)). In order to do this one can use information theory concepts, which gain the information only from the distribution of probability, which can be expressed easily from the contingency table by the relative frequencies.},
  language = {en},
  journal = {Wikipedia},
  month = feb,
  year = {2018},
  file = {/Users/zhangy4/Zotero/storage/8WFUCHRA/index.html},
  note = {Page Version ID: 823753141}
}

@article{f.r.s_criterion_1900,
  title = {X. {{On}} the Criterion That a given System of Deviations from the Probable in the Case of a Correlated System of Variables Is Such That It Can Be Reasonably Supposed to Have Arisen from Random Sampling},
  volume = {50},
  issn = {1941-5982},
  doi = {10.1080/14786440009463897},
  number = {302},
  journal = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
  author = {F.R.S, Karl Pearson},
  month = jul,
  year = {1900},
  pages = {157--175},
  file = {/Users/zhangy4/Zotero/storage/FGYM378P/14786440009463897.html}
}

@misc{_chisquare_,
  title = {9.1 - {{Chi}}-{{Square Test}} of {{Independence}} | {{STAT}} 500},
  howpublished = {https://onlinecourses.science.psu.edu/stat500/node/56},
  file = {/Users/zhangy4/Zotero/storage/22VBTH6L/56.html}
}

@article{_joint_2017,
  title = {Joint Probability Distribution},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {In the study of probability, given at least two random variables X, Y, ..., that are defined on a probability space, the joint probability distribution for X, Y, ... is a probability distribution that gives the probability that each of X, Y, ... falls in any particular range or discrete set of values specified for that variable. In the case of only two random variables, this is called a bivariate distribution, but the concept generalizes to any number of random variables, giving a multivariate distribution.
The joint probability distribution can be expressed either in terms of a joint cumulative distribution function or in terms of a joint probability density function (in the case of continuous variables) or joint probability mass function (in the case of discrete variables). These in turn can be used to find two other types of distributions: the marginal distribution giving the probabilities for any one of the variables with no reference to any specific ranges of values for the other variables, and the conditional probability distribution giving the probabilities for any subset of the variables conditional on particular values of the remaining variables.},
  language = {en},
  journal = {Wikipedia},
  month = oct,
  year = {2017},
  file = {/Users/zhangy4/Zotero/storage/N3EQU2L5/index.html},
  note = {Page Version ID: 805340328}
}

@article{fisher_interpretation_1922,
  title = {On the {{Interpretation}} of $X$2 from {{Contingency Tables}}, and the {{Calculation}} of {{P}}},
  volume = {85},
  issn = {0952-8385},
  doi = {10.2307/2340521},
  number = {1},
  journal = {Journal of the Royal Statistical Society},
  author = {Fisher, R. A.},
  year = {1922},
  pages = {87--94}
}

@article{hauck_comparative_1984,
  title = {A {{Comparative Study}} of {{Conditional Maximum Likelihood Estimation}} of a {{Common Odds Ratio}}},
  volume = {40},
  issn = {0006-341X},
  doi = {10.2307/2531163},
  abstract = {The finite-sample properties of various point estimators of a common odds ratio from multiple 2 x 2 tables have been considered in a number of simulation studies. However, the conditional maximum likelihood estimator has received only limited attention. That omission is partially rectified here for cases of relatively small numbers of tables and moderate to large within-table sample sizes. The conditional maximum likelihood estimator is found to be superior to the unconditional maximum likelihood estimator, and equal or superior to the Mantel-Haenszel estimator in both bias and precision.},
  number = {4},
  journal = {Biometrics},
  author = {Hauck, Walter W.},
  year = {1984},
  pages = {1117--1123}
}

@misc{_twoway_,
  title = {3.3 - {{Two}}-Way {{Tables}} - {{Exact Tests}} | {{STAT}} 504},
  howpublished = {https://onlinecourses.science.psu.edu/stat504/node/89},
  file = {/Users/zhangy4/Zotero/storage/QXR94FY6/89.html}
}

@article{agresti_survey_1992,
  title = {A {{Survey}} of {{Exact Inference}} for {{Contingency Tables}}},
  volume = {7},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/ss/1177011454},
  abstract = {The past decade has seen substantial research on exact inference for contingency tables, both in terms of developing new analyses and developing efficient algorithms for computations. Coupled with concomitant improvements in computer power, this research has resulted in a greater variety of exact procedures becoming feasible for practical use and a considerable increase in the size of data sets to which the procedures can be applied. For some basic analyses of contingency tables, it is unnecessary to use large-sample approximations to sampling distributions when their adequacy is in doubt. This article surveys the current theoretical and computational developments of exact methods for contingency tables. Primary attention is given to the exact conditional approach, which eliminates nuisance parameters by conditioning on their sufficient statistics. The presentation of various exact inferences is unified by expressing them in terms of parameters and their sufficient statistics in loglinear models. Exact approaches for many inferences are not yet addressed in the literature, particularly for multidimensional contingency tables, and this article also suggests additional research for the next decade that would make exact methods yet more widely applicable.},
  language = {EN},
  number = {1},
  journal = {Statistical Science},
  author = {Agresti, Alan},
  month = feb,
  year = {1992},
  keywords = {Categorical data,chi-squared tests,computational algorithms,conditional inference,Fisher's exact test,logistic regression,loglinear models,odds ratios,sufficient statistics},
  pages = {131--153},
  file = {/Users/zhangy4/Zotero/storage/CMRU68Q7/1177011454.html}
}

@article{_cartesian_2017a,
  title = {Cartesian Product},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {In set theory (and, usually, in other parts of mathematics), a Cartesian product is a mathematical operation that returns a set (or product set or simply product) from multiple sets. That is, for sets A and B, the Cartesian product A \texttimes{} B is the set of all ordered pairs (a, b) where a $\in$ A and b $\in$ B. Products can be specified using set-builder notation, e.g.

  
    
      
        A
        \texttimes
        B
        =
        \{
        
        (
        a
        ,
        b
        )
        $\mid$
        a
        $\in$
        A
         
        
          
             and 
          
        
         
        b
        $\in$
        B
        
        \}
        .
      
    
    \{$\backslash$displaystyle A$\backslash$times B=$\backslash$\{$\backslash$,(a,b)$\backslash$mid a$\backslash$in A$\backslash$ \{$\backslash$mbox\{ and \}\}$\backslash$ b$\backslash$in B$\backslash$,$\backslash$\}.\}
  
A table can be created by taking the Cartesian product of a set of rows and a set of columns. If the Cartesian product rows \texttimes{} columns is taken, the cells of the table contain ordered pairs of the form (row value, column value).
More generally, a Cartesian product of n sets, also known as an n-fold Cartesian product, can be represented by an array of n dimensions, where each element is an n-tuple. An ordered pair is a 2-tuple or couple.
The Cartesian product is named after Ren{\'e} Descartes, whose formulation of analytic geometry gave rise to the concept, which is further generalized in terms of direct product.},
  language = {en},
  journal = {Wikipedia},
  month = nov,
  year = {2017},
  file = {/Users/zhangy4/Zotero/storage/GKBXBW28/index.html},
  note = {Page Version ID: 808407129}
}

@article{_hypergeometric_2018a,
  title = {Hypergeometric Distribution},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {In probability theory and statistics, the hypergeometric distribution is a discrete probability distribution that describes the probability of 
  
    
      
        k
      
    
    \{$\backslash$displaystyle k\}
   successes (random draws for which the object drawn has a specified feature) in 
  
    
      
        n
      
    
    \{$\backslash$displaystyle n\}
   draws, without replacement, from a finite population of size 
  
    
      
        N
      
    
    \{$\backslash$displaystyle N\}
   that contains exactly 
  
    
      
        K
      
    
    \{$\backslash$displaystyle K\}
   objects with that feature, wherein each draw is either a success or a failure. In contrast, the binomial distribution describes the probability of 
  
    
      
        k
      
    
    \{$\backslash$displaystyle k\}
   successes in 
  
    
      
        n
      
    
    \{$\backslash$displaystyle n\}
   draws with replacement.
In statistics, the hypergeometric test uses the hypergeometric distribution to calculate the statistical significance of having drawn a specific 
  
    
      
        k
      
    
    \{$\backslash$displaystyle k\}
   successes (out of 
  
    
      
        n
      
    
    \{$\backslash$displaystyle n\}
   total draws) from the aforementioned population. The test is often used to identify which sub-populations are over- or under-represented in a sample. This test has a wide range of applications. For example, a marketing group could use the test to understand their customer base by testing a set of known customers for over-representation of various demographic subgroups (e.g., women, people under 30).},
  language = {en},
  journal = {Wikipedia},
  month = jan,
  year = {2018},
  file = {/Users/zhangy4/Zotero/storage/VJ5DSC7N/index.html},
  note = {Page Version ID: 823384543}
}

@misc{_hypothesis_,
  title = {Hypothesis Testing - {{Is}} "Test Statistic" a Value or a Random Variable? - {{Cross Validated}}},
  shorttitle = {Hypothesis Testing - {{Is}} "Test Statistic" a Value or a Random Variable?},
  howpublished = {https://stats.stackexchange.com/questions/85426/is-test-statistic-a-value-or-a-random-variable},
  file = {/Users/zhangy4/Zotero/storage/L259A9XS/is-test-statistic-a-value-or-a-random-variable.html}
}

@article{_exact_2017,
  title = {Exact Test},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {In statistics, an exact (significance) test is a test where all assumptions, upon which the derivation of the distribution of the test statistic is based, are met as opposed to an approximate test (in which the approximation may be made as close as desired by making the sample size big enough). This will result in a significance test that will have a false rejection rate always equal to the significance level of the test. For example an exact test at significance level 5\% will in the long run reject true null hypotheses exactly 5\% of the time.
Parametric tests, such as those described in exact statistics, are exact tests when the parametric assumptions are fully met, but in practice the use of the term exact (significance) test is reserved for those tests that do not rest on parametric assumptions \textendash{} non-parametric tests. However, in practice most implementations of non-parametric test software use asymptotical algorithms for obtaining the significance value, which makes the implementation of the test non-exact.
So when the result of a statistical analysis is said to be an ``exact test'' or an ``exact p-value'', it ought to imply that the test is defined without parametric assumptions and evaluated without using approximate algorithms. In principle however it could also mean that a parametric test has been employed in a situation where all parametric assumptions are fully met, but it is in most cases impossible to prove this completely in a real world situation. Exceptions when it is certain that parametric tests are exact include tests based on the binomial or Poisson distributions. Sometimes permutation test is used as a synonym for exact test, but although all permutation tests are exact tests, not all exact tests are permutation tests.},
  language = {en},
  journal = {Wikipedia},
  month = aug,
  year = {2017},
  file = {/Users/zhangy4/Zotero/storage/PHAN2X2S/index.html},
  note = {Page Version ID: 793430439}
}

@misc{_hypergeometric_,
  title = {Hypergeometric {{Distribution}} | {{STAT}} 414 / 415},
  howpublished = {https://onlinecourses.science.psu.edu/stat414/node/58},
  file = {/Users/zhangy4/Zotero/storage/MUAA2Y9U/58.html}
}

@article{_combinatorics_2017,
  title = {Combinatorics},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {Combinatorics is an area of mathematics primarily concerned with counting, both as a means and an end in obtaining results, and certain properties of finite structures. It is closely related to many other areas of mathematics and has many applications ranging from logic to statistical physics, from evolutionary biology to computer science, etc.
To fully understand the scope of combinatorics requires a great deal of further amplification, the details of which are not universally agreed upon. According to H. J. Ryser, a definition of the subject is difficult because it crosses so many mathematical subdivisions. In so far as an area can be described by the types of problems it addresses, combinatorics is involved with
the enumeration (counting) of specified structures, sometimes referred to as arrangements or configurations in a very general sense, associated with finite systems,
the existence of such structures that satisfy certain given criteria,
the construction of these structures, perhaps in many ways, and
optimization, finding the "best" structure or solution among several possibilities, be it the "largest", "smallest" or satisfying some other optimality criterion.
Leon Mirsky has said: "combinatorics is a range of linked studies which have something in common and yet diverge widely in their objectives, their methods, and the degree of coherence they have attained." One way to define combinatorics is, perhaps, to describe its subdivisions with their problems and techniques. This is the approach that is used below. However, there are also purely historical reasons for including or not including some topics under the combinatorics umbrella. Although primarily concerned with finite systems, some combinatorial questions and techniques can be extended to an infinite (specifically, countable) but discrete setting.
Combinatorics is well known for the breadth of the problems it tackles. Combinatorial problems arise in many areas of pure mathematics, notably in algebra, probability theory, topology, and geometry, as well as in its many application areas. Many combinatorial questions have historically been considered in isolation, giving an ad hoc solution to a problem arising in some mathematical context. In the later twentieth century, however, powerful and general theoretical methods were developed, making combinatorics into an independent branch of mathematics in its own right. One of the oldest and most accessible parts of combinatorics is graph theory, which by itself has numerous natural connections to other areas. Combinatorics is used frequently in computer science to obtain formulas and estimates in the analysis of algorithms.
A mathematician who studies combinatorics is called a combinatorialist.},
  language = {en},
  journal = {Wikipedia},
  month = nov,
  year = {2017},
  file = {/Users/zhangy4/Zotero/storage/WPTJQY2A/index.html},
  note = {Page Version ID: 808835904}
}

@article{_vandermonde_2017,
  title = {Vandermonde's Identity},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {In combinatorics, Vandermonde's identity (or Vandermonde's convolution) is the following identity for binomial coefficients:

  
    
      
        
          
            
              (
            
            
              
                m
                +
                n
              
              r
            
            
              )
            
          
        
        =
        
          $\sum$
          
            k
            =
            0
          
          
            r
          
        
        
          
            
              (
            
            
              m
              k
            
            
              )
            
          
        
        
          
            
              (
            
            
              n
              
                r
                -
                k
              
            
            
              )
            
          
        
      
    
    \{$\backslash$displaystyle \{m+n $\backslash$choose r\}=$\backslash$sum \_\{k=0\}\^\{r\}\{m $\backslash$choose k\}\{n $\backslash$choose r-k\}\}
  
for any nonnegative integers r, m, n. The identity is named after Alexandre-Th{\'e}ophile Vandermonde (1772), although it was already known in 1303 by the Chinese mathematician Zhu Shijie (Chu Shi-Chieh). See Askey 1975, pp. 59\textendash{}60 for the history.
There is a q-analog to this theorem called the q-Vandermonde identity.
Vandermonde's identity can be generalized in numerous ways, including to the identity

  
    
      
        
          
            
              (
            
            
              
                
                  n
                  
                    1
                  
                
                +
                $\cdots$
                +
                
                  n
                  
                    p
                  
                
              
              m
            
            
              )
            
          
        
        =
        
          $\sum$
          
            
              k
              
                1
              
            
            +
            $\cdots$
            +
            
              k
              
                p
              
            
            =
            m
          
        
        
          
            
              (
            
            
              
                n
                
                  1
                
              
              
                k
                
                  1
                
              
            
            
              )
            
          
        
        
          
            
              (
            
            
              
                n
                
                  2
                
              
              
                k
                
                  2
                
              
            
            
              )
            
          
        
        $\cdots$
        
          
            
              (
            
            
              
                n
                
                  p
                
              
              
                k
                
                  p
                
              
            
            
              )
            
          
        
      
    
    \{$\backslash$displaystyle \{n\_\{1\}+$\backslash$dots +n\_\{p\} $\backslash$choose m\}=$\backslash$sum \_\{k\_\{1\}+$\backslash$cdots +k\_\{p\}=m\}\{n\_\{1\} $\backslash$choose k\_\{1\}\}\{n\_\{2\} $\backslash$choose k\_\{2\}\}$\backslash$cdots \{n\_\{p\} $\backslash$choose k\_\{p\}\}\}
  .},
  language = {en},
  journal = {Wikipedia},
  month = nov,
  year = {2017},
  file = {/Users/zhangy4/Zotero/storage/HJJ7QH23/index.html},
  note = {Page Version ID: 811396357}
}


